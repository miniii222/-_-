{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout, Embedding, Flatten, Input, merge\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.models import Model\n",
    "\n",
    "from time import time\n",
    "import datetime\n",
    "from itertools import combinations\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse, mod\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "train_label = train['target']\n",
    "train_id = train['id']\n",
    "\n",
    "del train['target'], train['id']\n",
    "\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "test_id = test['id']\n",
    "del test['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기초 통계 변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj_num_on_cat(train_df, test_df, target_column, group_column) :\n",
    "    \n",
    "    train_df['row_id'] = range(train_df.shape[0])\n",
    "    test_df['row_id'] = range(test_df.shape[0])\n",
    "    train_df['train'] = 1; test_df['train'] = 0\n",
    "    \n",
    "    #train + test\n",
    "    all_df = train_df[['row_id','train',target_column, group_column]].append(test_df[['row_id','train',target_column, group_column]])\n",
    "    grouped = all_df[[target_column, group_column]].groupby(group_column)\n",
    "    \n",
    "    #size, mean, median, max, min\n",
    "    the_size = pd.DataFrame(grouped.size()).reset_index()\n",
    "    the_size.columns = [group_column, '%s_size' % target_column]\n",
    "    the_mean = pd.DataFrame(grouped.mean()).reset_index()\n",
    "    the_mean.columns = [group_column, '%s_mean' % target_column]\n",
    "    the_std = pd.DataFrame(grouped.std()).reset_index()\n",
    "    the_std.columns = [group_column, '%s_std' % target_column]\n",
    "    the_median = pd.DataFrame(grouped.median()).reset_index()\n",
    "    the_median.columns = [group_column, '%s_median' % target_column]\n",
    "    the_max = pd.DataFrame(grouped.max()).reset_index()\n",
    "    the_max.columns = [group_column, '%s_max' % target_column]\n",
    "    the_min = pd.DataFrame(grouped.min()).reset_index()\n",
    "    the_min.columns = [group_column, '%s_min' % target_column]\n",
    "    \n",
    "    #통게 기반 파생 변수\n",
    "    the_stats = pd.merge(the_size, the_mean)\n",
    "    the_stats = pd.merge(the_stats, the_std)\n",
    "    the_stats = pd.merge(the_stats, the_median)\n",
    "    the_stats = pd.merge(the_stats, the_max)\n",
    "    the_stats = pd.merge(the_stats, the_min)\n",
    "    \n",
    "    all_df = pd.merge(all_df, the_stats, how = 'left')\n",
    "    \n",
    "    #split train ,test\n",
    "    selected_train = all_df[all_df.train == 1]\n",
    "    selected_test = all_df[all_df.train == 0]\n",
    "    \n",
    "    selected_train.sort_values('row_id', inplace = True)\n",
    "    selected_test.sort_values('row_id', inplace = True)\n",
    "    \n",
    "    selected_train.drop([target_column, group_column,'row_id','train'], axis = 1, inplace = True)\n",
    "    selected_test.drop([target_column, group_column,'row_id','train'], axis = 1, inplace = True)\n",
    "    \n",
    "    selected_train, selected_test = np.array(selected_train), np.array(selected_test)\n",
    "    \n",
    "    return selected_train, selected_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 변수 간의 다양한 상호 작용 파생 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interaction_features(train ,test, fea1, fea2, prefix) :\n",
    "    train['inter_{}*'.format(prefix)] = train[fea1] * train[fea2]\n",
    "    train['inter_{}/'.format(prefix)] = train[fea1] / train[fea2]\n",
    "    \n",
    "    test['inter_{}*'.format(prefix)] = test[fea1] * test[fea2]\n",
    "    test['inter_{}/'.format(prefix)] = test[fea1] / test[fea2]\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_fea = [x for x in list(train) if 'cat' in x]\n",
    "bin_fea = [x for x in list(train) if 'bin' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the number of -1(NA)\n",
    "train['missing'] = (train==-1).sum(axis = 1).astype(float)\n",
    "test['missing'] = (test==-1).sum(axis = 1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combination : 전체 리스트 n 개에서 2개씩 짝 지은 nC2의 모든 경우를 모두 보여줌\n",
    "for e,(x,y) in enumerate(combinations(['ps_car_13','ps_ind_03','ps_reg_03','ps_ind_15','ps_reg_01','ps_ind_01'],2)) :\n",
    "    train, test = interaction_features(train, test, x, y, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(train)\n",
    "\n",
    "num_features = [c for c in feature_names if ('cat' not in c and 'calc' not in c)]\n",
    "num_features.append('missing')\n",
    "\n",
    "inter_features = [x for x in feature_names if 'inter' in x]\n",
    "\n",
    "ind_features = [c for c in feature_names if 'ind' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for c in ind_features :\n",
    "    if count == 0 :\n",
    "        train['new_ind'] = train[c].astype(str)\n",
    "        count += 1\n",
    "    else :\n",
    "        train['new_ind'] += '_' + train[c].astype(str)\n",
    "count = 0        \n",
    "for c in ind_features :\n",
    "    if count == 0 :\n",
    "        test['new_ind'] = test[c].astype(str)\n",
    "        count +=1\n",
    "    else :\n",
    "        test['new_ind'] += '_' + test[c].astype(str)\n",
    "        \n",
    "\n",
    "reg_features = [c for c in feature_names if 'reg' in c]\n",
    "count = 0\n",
    "for c in reg_features :\n",
    "    if count == 0 :\n",
    "        train['new_reg'] = train[c].astype(str)\n",
    "        count += 1\n",
    "    else :\n",
    "        train['new_reg'] += '_' + train[c].astype(str)\n",
    "count = 0\n",
    "for c in reg_features :\n",
    "    if count == 0 :\n",
    "        test['new_reg'] = test[c].astype(str)\n",
    "        count += 1\n",
    "    else :\n",
    "        test['new_reg'] += '_' + test[c].astype(str)\n",
    "\n",
    "        \n",
    "car_features = [c for c in feature_names if 'car' in c]\n",
    "count = 0\n",
    "for c in car_features :\n",
    "    if count == 0 :\n",
    "        train['new_car'] = train[c].astype(str)\n",
    "        count += 1\n",
    "    else :\n",
    "        train['new_car'] += '_' + train[c].astype(str)\n",
    "count = 0\n",
    "for c in car_features :\n",
    "    if count == 0 :\n",
    "        test['new_car'] = test[c].astype(str)\n",
    "        count += 1\n",
    "    else :\n",
    "        test['new_car'] += '_' + test[c].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat = train[cat_fea]\n",
    "train_num = train[[x for x in list(train) if x in num_features]]\n",
    "test_cat = test[cat_fea]\n",
    "test_num = test[[x for x in list(train) if x in num_features]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "max_cat_values = [] #라벨 인코딩을 하게 되면, 1,2,3,... 등으로 labeling이 되는데, max 값을 취하면 category의 개수?\n",
    "\n",
    "for c in cat_fea :\n",
    "    \n",
    "    x = le.fit_transform(pd.concat([train_cat, test_cat])[c])\n",
    "    \n",
    "    train_cat[c] = le.transform(train_cat[c])\n",
    "    test_cat[c] = le.transform(test_cat[c])\n",
    "    \n",
    "    max_cat_values.append(np.max(x))\n",
    "    \n",
    "#카테고리 변수들을 label encoding 한 후\n",
    "#각 값들의 카운트 수를 다시 새로운 피쳐로!\n",
    "\n",
    "cat_count_features = []\n",
    "for c in cat_fea + ['new_ind', 'new_reg','new_car'] :\n",
    "    d = pd.concat([train[c], test[c]]).value_counts().to_dict()\n",
    "    \n",
    "    train['%s_count'%c] = train[c].apply(lambda x : d.get(x,0))\n",
    "    test['%s_count'%c] = test[c].apply(lambda x : d.get(x,0))\n",
    "    cat_count_features.append('%s_count'%c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import Xgboost features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fea0, test_fea0 = pickle.load(open('./data/fea0.pk', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace inf, nan -> 0 in numeric data\n",
    "train_list = [train_num.replace([np.inf, -np.inf, np.nan], 0), train[cat_count_features], train_fea0]\n",
    "test_list = [test_num.replace([np.inf, -np.inf, np.nan],0), test[cat_count_features], test_fea0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "for t in ['ps_car_13', 'ps_ind_03', 'ps_reg_03', 'ps_ind_15', 'ps_reg_01', 'ps_ind_01'] :\n",
    "    for g in ['ps_car_13', 'ps_ind_03', 'ps_reg_03', 'ps_ind_15', 'ps_reg_01', 'ps_ind_01', 'ps_ind_05_cat'] :\n",
    "        if t!=g :\n",
    "            s_train, s_test = proj_num_on_cat(train, test, target_column=t, group_column=g)\n",
    "            train_list.append(s_train)\n",
    "            test_list.append(s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sparse.hstack(train_list).tocsr()\n",
    "X_test = sparse.hstack(test_list).tocsr()\n",
    "all_data = np.vstack([X.toarray(), X_test.toarray()])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(all_data)\n",
    "\n",
    "X = scaler.transform(X.toarray())\n",
    "X_test = scaler.transform(X_test.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "왜 위의 피쳐들만 이용해서 조합을 만들었는지는 알 수 없다 ㅜㅡㅜ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchNormalization\t Dense\t Dropout\t Embedding\t Flatten\t Input\t LabelEncoder\t Model\t PReLU\t \n",
      "StandardScaler\t StratifiedKFold\t X\t X_test\t all_data\t bin_fea\t c\t car_features\t cat_count_features\t \n",
      "cat_fea\t combinations\t count\t d\t datetime\t e\t feature_names\t g\t ind_features\t \n",
      "inter_fea\t interaction_features\t le\t max_cat_values\t merge\t mod\t np\t num_features\t pd\t \n",
      "pickle\t proj_num_on_cat\t reg_features\t s_test\t s_train\t scaler\t sparse\t t\t test\t \n",
      "test_cat\t test_fea0\t test_id\t test_list\t test_num\t time\t train\t train_cat\t train_fea0\t \n",
      "train_id\t train_label\t train_list\t train_num\t x\t y\t \n"
     ]
    }
   ],
   "source": [
    "def nn_model() :\n",
    "    inputs = []\n",
    "    flatten_layers = []\n",
    "    \n",
    "    for e, c in enumerate(cat_fea) :\n",
    "        input_c = Input(shape = (1,), dtype = 'int32')\n",
    "        num_c = max_cat_values[e]\n",
    "        embed_c = Embedding(num_c, 6, input_length = 1)(inpu_c)\n",
    "        embed_c = Dropout(0.25)(embed_c)\n",
    "        flatten_c = Flatten()(embed_c)\n",
    "        inputs.append(input_c)\n",
    "        flatten_layers.append(flatten_c)\n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
