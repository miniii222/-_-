{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train.csv', 'test.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.listdir('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "train_label = train['target']\n",
    "train_id = train.id\n",
    "\n",
    "del train['target'], train['id']\n",
    "\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "test_id = test.id\n",
    "\n",
    "del test['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FE\n",
    "## missing\n",
    "- 결측치의 개수가 데이터 내에 새로운 군집 정보를 제공할 수 있다고 생각\n",
    "- 새로운 운전자의 경우 결측값이 더 많이 존재할 수 있다\n",
    "- 또 특정 지점에서 DB의 문제로 열 정보가 사라졌을 떄, 간접적인 정보로 표현 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -1 : NA\n",
    "train['missing'] = (train == -1).sum(axis = 1)\n",
    "test['missing'] = (test == -1).sum(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sum of binary value\n",
    "- 변수 간의 상호 작용으로 얻을 수 있는 고차원 정보를 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_features = [c for c in train.columns if 'bin' in c]\n",
    "train['bin_sum'] = train[bin_features].sum(axis = 1)\n",
    "test['bin_sum'] = test[bin_features].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## target encoding\n",
    "- 선별한 일부 변수를 대상으로 수행(bar plot을 통해서 변수별로 target값의 차이가 있어 보이는 변수들을 활용)\n",
    "- 단일 변수의 고유값별 타겟 변수의 평균값을 파생 변수로 활용\n",
    "- 타겟 변수의 값을 직접적으로 사용하는 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ps_ind_01', 'ps_ind_02_cat', 'ps_ind_03', 'ps_ind_04_cat',\n",
       "       'ps_ind_05_cat', 'ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin',\n",
       "       'ps_ind_09_bin', 'ps_ind_10_bin', 'ps_ind_11_bin', 'ps_ind_12_bin',\n",
       "       'ps_ind_13_bin', 'ps_ind_14', 'ps_ind_15', 'ps_ind_16_bin',\n",
       "       'ps_ind_17_bin', 'ps_ind_18_bin', 'ps_reg_01', 'ps_reg_02', 'ps_reg_03',\n",
       "       'ps_car_01_cat', 'ps_car_02_cat', 'ps_car_03_cat', 'ps_car_04_cat',\n",
       "       'ps_car_05_cat', 'ps_car_06_cat', 'ps_car_07_cat', 'ps_car_08_cat',\n",
       "       'ps_car_09_cat', 'ps_car_10_cat', 'ps_car_11_cat', 'ps_car_11',\n",
       "       'ps_car_12', 'ps_car_13', 'ps_car_14', 'ps_car_15', 'ps_calc_01',\n",
       "       'ps_calc_02', 'ps_calc_03', 'ps_calc_04', 'ps_calc_05', 'ps_calc_06',\n",
       "       'ps_calc_07', 'ps_calc_08', 'ps_calc_09', 'ps_calc_10', 'ps_calc_11',\n",
       "       'ps_calc_12', 'ps_calc_13', 'ps_calc_14', 'ps_calc_15_bin',\n",
       "       'ps_calc_16_bin', 'ps_calc_17_bin', 'ps_calc_18_bin', 'ps_calc_19_bin',\n",
       "       'ps_calc_20_bin', 'missing', 'bin_sum'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin','ps_ind_09_bin', \n",
    "            'ps_ind_12_bin', 'ps_ind_16_bin','ps_ind_17_bin', 'ps_ind_18_bin',\n",
    "            'ps_ind_04_cat','ps_ind_05_cat','ps_car_01_cat', 'ps_car_02_cat', 'ps_car_03_cat', 'ps_car_04_cat',\n",
    "            'ps_car_06_cat', 'ps_car_07_cat', 'ps_ind_01','ps_ind_03','ps_ind_15','ps_car_11']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_boost_round = 10000\n",
    "params = {'objective' : 'binary',\n",
    "         'boosting_type' : 'gbdt',\n",
    "         'learning_rate' : 0.1,\n",
    "         'num_leaves' : 15,\n",
    "         'max_bin' : 256,\n",
    "         'feature_fraction' : 0.6,\n",
    "         'verbosity' : 0,\n",
    "         'drop_rate' : 0.1,\n",
    "         'is_unbalance' : False,\n",
    "         'max_drop' : 50,\n",
    "         'min_child_samples' : 10,\n",
    "         'min_child_weight' : 150,\n",
    "         'min_split_gain' : 0,\n",
    "         'subsmaple' : 0.9,\n",
    "         'seed' : 2018,\n",
    "         'n_jobs' : -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gini(y_true, y_pred):\n",
    "    # check and get number of samples\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    n_samples = y_true.shape[0]\n",
    "\n",
    "    # sort rows on prediction column\n",
    "    # (from largest to smallest)\n",
    "    arr = np.array([y_true, y_pred]).transpose()\n",
    "    true_order = arr[arr[:, 0].argsort()][::-1, 0]\n",
    "    pred_order = arr[arr[:, 1].argsort()][::-1, 0]\n",
    "\n",
    "    # get Lorenz curves\n",
    "    L_true = np.cumsum(true_order) * 1. / np.sum(true_order)\n",
    "    L_pred = np.cumsum(pred_order) * 1. / np.sum(pred_order)\n",
    "    L_ones = np.linspace(1 / n_samples, 1, n_samples)\n",
    "\n",
    "    # get Gini coefficients (area between curves)\n",
    "    G_true = np.sum(L_ones - L_true)\n",
    "    G_pred = np.sum(L_ones - L_pred)\n",
    "\n",
    "    # normalize to true Gini coefficient\n",
    "    return G_pred * 1. / G_true\n",
    "\n",
    "\n",
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'gini', Gini(labels, preds), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "NFOLDS = 5\n",
    "kfold = StratifiedKFold(n_splits = NFOLDS, shuffle = True, random_state=218)\n",
    "kf = kfold.split(train, train_label)\n",
    "\n",
    "cv_train = np.zeros(len(train_label))\n",
    "cv_pred = np.zeros(len(test_id))\n",
    "best_trees = []\n",
    "fold_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152193\tvalid_0's gini: 0.277277\n",
      "[200]\tvalid_0's binary_logloss: 0.152162\tvalid_0's gini: 0.27859\n",
      "Early stopping, best iteration is:\n",
      "[151]\tvalid_0's binary_logloss: 0.152125\tvalid_0's gini: 0.279835\n",
      "0.2798346884236375\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151813\tvalid_0's gini: 0.281267\n",
      "[200]\tvalid_0's binary_logloss: 0.15187\tvalid_0's gini: 0.279366\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid_0's binary_logloss: 0.151798\tvalid_0's gini: 0.282089\n",
      "0.28208945536561003\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151668\tvalid_0's gini: 0.287244\n",
      "[200]\tvalid_0's binary_logloss: 0.151759\tvalid_0's gini: 0.285428\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's binary_logloss: 0.151659\tvalid_0's gini: 0.287601\n",
      "0.28760084772746447\n"
     ]
    }
   ],
   "source": [
    "for i, (train_idx, valid_idx) in enumerate(kf) :\n",
    "    X_train, y_train = train.iloc[train_idx, :], train_label[train_idx]\n",
    "    X_valid, y_valid = train.iloc[valid_idx, :], train_label[valid_idx]\n",
    "    \n",
    "    for feature in features :\n",
    "        map_dict = pd.DataFrame([X_train[feature], y_train]).T.groupby(feature).agg('mean')\n",
    "        map_dict = map_dict.to_dict()['target']\n",
    "        \n",
    "        X_train[feature + '_target_enc'] = X_train[feature].apply(lambda x : map_dict.get(x,0))\n",
    "        X_valid[feature + '_target_enc'] = X_valid[feature].apply(lambda x : map_dict.get(x,0))\n",
    "        test[feature + '_target_enc'] = test[feature].apply(lambda x : map_dict.get(x,0))\n",
    "        \n",
    "    dtrain = lgb.Dataset(X_train, y_train)\n",
    "    dvalid = lgb.Dataset(X_valid, y_valid)\n",
    "    \n",
    "    bst = lgb.train(params, dtrain, num_boost_round, valid_sets=dvalid,\n",
    "                   feval = evalerror, verbose_eval=100, early_stopping_rounds=100)\n",
    "    \n",
    "    best_trees.append(bst.best_iteration)\n",
    "    \n",
    "    cv_pred += bst.predict(test, num_iteration=bst.best_iteration)\n",
    "    cv_train[valid_idx] += bst.predict(X_valid)\n",
    "    \n",
    "    score = Gini(y_valid, cv_train[valid_idx])\n",
    "    print(score)\n",
    "    fold_scores.append(score)\n",
    "    \n",
    "cv_pred /= NFOLDS\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score :  0.17956604017228467\n",
      "[0.2798346884236375, 0.28208945536561003, 0.28760084772746447]\n",
      "[95, 151, 114, 109] 117.25\n"
     ]
    }
   ],
   "source": [
    "print('cv score : ', Gini(train_label, cv_train))\n",
    "print(fold_scores)\n",
    "print(best_trees, np.mean(best_trees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
